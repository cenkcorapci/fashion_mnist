{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2c3412a4-039b-4229-9387-9321169f16eb",
    "_uuid": "8def9627e9d48b26de3159fc9a2ec38e854ab16e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 20:57:14,031 : INFO : Checking/creating directories...\n",
      "2019-12-18 20:57:14,033 : INFO : Directories are set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dl.simple_cnn import SimpleCNN\n",
    "from dl.shuffle_net import ShuffleNetV2\n",
    "from dl.mobile_net import MobileNET\n",
    "from dl.wide_resnet import WideResNet\n",
    "from dl.capsule_net import CapsuleNet\n",
    "from dl.callbacks.plot_loss import PlotLosses\n",
    "from data.data_set import get_data\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from config import DL_MODELS_PATH, TB_LOGS_PATH\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from swa.tfkeras import SWA\n",
    "from dl.callbacks.cyclical_lr import CyclicLR\n",
    "from plotly.offline import init_notebook_mode\n",
    "from visualization.visualize_history import plot_accuracy_and_loss\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train, y_train), (X_val, y_val)) = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range= .8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = .1, # Randomly zoom image \n",
    "        width_shift_range= .1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range= .1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=.05,  # randomly flip images horizontally\n",
    "        vertical_flip=False)  # randomly flip images vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name, use_cyclic_lr=False, plot=False):\n",
    "    callbacks = [TerminateOnNaN(), EarlyStopping(monitor='val_accuracy', patience=5)]\n",
    "    callbacks.append(ModelCheckpoint(os.path.join(DL_MODELS_PATH, model_name + '-{epoch:02d}-{val_accuracy:.2f}.hdf5'), monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max'))\n",
    "    tb_path = os.path.join(TB_LOGS_PATH, model_name)\n",
    "    pathlib.Path(tb_path).mkdir(parents=True, exist_ok=True)\n",
    "    callbacks.append(TensorBoard(log_dir=tb_path))\n",
    "    callbacks.append(SWA(start_epoch=5, lr_schedule='constant', swa_lr=0.001, verbose=1))\n",
    "    if plot:\n",
    "        callbacks.append(PlotLosses())\n",
    "    if use_cyclic_lr:\n",
    "        callbacks.append(CyclicLR(base_lr=0.001, max_lr=0.006, step_size=2000.))\n",
    "    else:\n",
    "        rlronp =  ReduceLROnPlateau(monitor='val_loss',\n",
    "                                    patience=3,\n",
    "                                    verbose=1,\n",
    "                                    factor=0.5,\n",
    "                                    min_lr=0.00005)\n",
    "        \n",
    "        callbacks.append(rlronp)\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "Learning_rate = 0.001\n",
    "decay= 5 * Learning_rate / epochs\n",
    "optimizers = {'adam': Adam(lr=Learning_rate, decay= 3 * Learning_rate / epochs),\n",
    "              'rmsprop': RMSprop(lr=Learning_rate, rho=0.9, epsilon=1e-08, decay= 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 20:57:17,643 : WARNING : Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 20:57:17,729 : WARNING : Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "Resizing training images: 60000it [00:06, 9842.57it/s] \n",
      "Resizing training images: 10000it [00:00, 13009.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses batch normalization. SWA will require last epoch to be a forward pass and will run with no learning rate\n",
      "Epoch 1/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.6044 - accuracy: 0.7799 - categorical_crossentropy: 0.6044 - categorical_accuracy: 0.7799\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.78520, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-01-0.79.hdf5\n",
      "1875/1875 [==============================] - 428s 228ms/step - loss: 0.6043 - accuracy: 0.7800 - categorical_crossentropy: 0.6043 - categorical_accuracy: 0.7800 - val_loss: 0.5805 - val_accuracy: 0.7852 - val_categorical_crossentropy: 0.5807 - val_categorical_accuracy: 0.7852\n",
      "Epoch 2/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8606 - categorical_crossentropy: 0.3848 - categorical_accuracy: 0.8606\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.78520 to 0.85000, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-02-0.85.hdf5\n",
      "1875/1875 [==============================] - 425s 226ms/step - loss: 0.3847 - accuracy: 0.8607 - categorical_crossentropy: 0.3847 - categorical_accuracy: 0.8607 - val_loss: 0.4341 - val_accuracy: 0.8500 - val_categorical_crossentropy: 0.4342 - val_categorical_accuracy: 0.8500\n",
      "Epoch 3/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.3229 - accuracy: 0.8831 - categorical_crossentropy: 0.3229 - categorical_accuracy: 0.8831\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.85000 to 0.88610, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-03-0.89.hdf5\n",
      "1875/1875 [==============================] - 424s 226ms/step - loss: 0.3229 - accuracy: 0.8831 - categorical_crossentropy: 0.3229 - categorical_accuracy: 0.8831 - val_loss: 0.3171 - val_accuracy: 0.8861 - val_categorical_crossentropy: 0.3171 - val_categorical_accuracy: 0.8861\n",
      "Epoch 4/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.8978 - categorical_crossentropy: 0.2842 - categorical_accuracy: 0.8978\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.88610\n",
      "1875/1875 [==============================] - 422s 225ms/step - loss: 0.2844 - accuracy: 0.8977 - categorical_crossentropy: 0.2844 - categorical_accuracy: 0.8977 - val_loss: 0.3342 - val_accuracy: 0.8798 - val_categorical_crossentropy: 0.3342 - val_categorical_accuracy: 0.8798\n",
      "\n",
      "Epoch 00005: starting stochastic weight averaging\n",
      "Epoch 5/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9046 - categorical_crossentropy: 0.2643 - categorical_accuracy: 0.9046\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.88610 to 0.90840, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-05-0.91.hdf5\n",
      "1875/1875 [==============================] - 425s 227ms/step - loss: 0.2643 - accuracy: 0.9046 - categorical_crossentropy: 0.2643 - categorical_accuracy: 0.9046 - val_loss: 0.2538 - val_accuracy: 0.9084 - val_categorical_crossentropy: 0.2535 - val_categorical_accuracy: 0.9084\n",
      "Epoch 6/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9120 - categorical_crossentropy: 0.2424 - categorical_accuracy: 0.9120\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.90840\n",
      "1875/1875 [==============================] - 421s 225ms/step - loss: 0.2424 - accuracy: 0.9120 - categorical_crossentropy: 0.2424 - categorical_accuracy: 0.9120 - val_loss: 0.2619 - val_accuracy: 0.9081 - val_categorical_crossentropy: 0.2620 - val_categorical_accuracy: 0.9081\n",
      "Epoch 7/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9180 - categorical_crossentropy: 0.2266 - categorical_accuracy: 0.9180\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.90840 to 0.92050, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-07-0.92.hdf5\n",
      "1875/1875 [==============================] - 424s 226ms/step - loss: 0.2266 - accuracy: 0.9180 - categorical_crossentropy: 0.2266 - categorical_accuracy: 0.9180 - val_loss: 0.2256 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.2258 - val_categorical_accuracy: 0.9205\n",
      "Epoch 8/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2178 - accuracy: 0.9203 - categorical_crossentropy: 0.2178 - categorical_accuracy: 0.9203\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.92050 to 0.92220, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-08-0.92.hdf5\n",
      "1875/1875 [==============================] - 426s 227ms/step - loss: 0.2177 - accuracy: 0.9203 - categorical_crossentropy: 0.2177 - categorical_accuracy: 0.9203 - val_loss: 0.2218 - val_accuracy: 0.9222 - val_categorical_crossentropy: 0.2215 - val_categorical_accuracy: 0.9222\n",
      "Epoch 9/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.9243 - categorical_crossentropy: 0.2060 - categorical_accuracy: 0.9243\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.92220\n",
      "1875/1875 [==============================] - 421s 224ms/step - loss: 0.2060 - accuracy: 0.9243 - categorical_crossentropy: 0.2060 - categorical_accuracy: 0.9243 - val_loss: 0.2415 - val_accuracy: 0.9161 - val_categorical_crossentropy: 0.2414 - val_categorical_accuracy: 0.9161\n",
      "Epoch 10/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.9308 - categorical_crossentropy: 0.1928 - categorical_accuracy: 0.9308\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.92220 to 0.92950, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-10-0.93.hdf5\n",
      "1875/1875 [==============================] - 421s 225ms/step - loss: 0.1928 - accuracy: 0.9308 - categorical_crossentropy: 0.1928 - categorical_accuracy: 0.9308 - val_loss: 0.2005 - val_accuracy: 0.9295 - val_categorical_crossentropy: 0.2006 - val_categorical_accuracy: 0.9295\n",
      "Epoch 11/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.9320 - categorical_crossentropy: 0.1868 - categorical_accuracy: 0.9320\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.92950\n",
      "1875/1875 [==============================] - 422s 225ms/step - loss: 0.1867 - accuracy: 0.9321 - categorical_crossentropy: 0.1867 - categorical_accuracy: 0.9321 - val_loss: 0.2310 - val_accuracy: 0.9232 - val_categorical_crossentropy: 0.2306 - val_categorical_accuracy: 0.9232\n",
      "Epoch 12/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9352 - categorical_crossentropy: 0.1798 - categorical_accuracy: 0.9352\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.92950\n",
      "1875/1875 [==============================] - 421s 225ms/step - loss: 0.1798 - accuracy: 0.9352 - categorical_crossentropy: 0.1798 - categorical_accuracy: 0.9352 - val_loss: 0.2256 - val_accuracy: 0.9175 - val_categorical_crossentropy: 0.2258 - val_categorical_accuracy: 0.9175\n",
      "Epoch 13/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9369 - categorical_crossentropy: 0.1712 - categorical_accuracy: 0.9369\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.92950 to 0.93250, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-13-0.93.hdf5\n",
      "1875/1875 [==============================] - 424s 226ms/step - loss: 0.1712 - accuracy: 0.9370 - categorical_crossentropy: 0.1712 - categorical_accuracy: 0.9370 - val_loss: 0.1933 - val_accuracy: 0.9325 - val_categorical_crossentropy: 0.1934 - val_categorical_accuracy: 0.9325\n",
      "Epoch 14/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 0.9399 - categorical_crossentropy: 0.1655 - categorical_accuracy: 0.9399\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.93250 to 0.93840, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-14-0.94.hdf5\n",
      "1875/1875 [==============================] - 425s 226ms/step - loss: 0.1656 - accuracy: 0.9399 - categorical_crossentropy: 0.1656 - categorical_accuracy: 0.9399 - val_loss: 0.1750 - val_accuracy: 0.9384 - val_categorical_crossentropy: 0.1751 - val_categorical_accuracy: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9419 - categorical_crossentropy: 0.1607 - categorical_accuracy: 0.9419\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.93840 to 0.93870, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-15-0.94.hdf5\n",
      "1875/1875 [==============================] - 421s 224ms/step - loss: 0.1607 - accuracy: 0.9419 - categorical_crossentropy: 0.1607 - categorical_accuracy: 0.9419 - val_loss: 0.1774 - val_accuracy: 0.9387 - val_categorical_crossentropy: 0.1774 - val_categorical_accuracy: 0.9387\n",
      "Epoch 16/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9437 - categorical_crossentropy: 0.1547 - categorical_accuracy: 0.9437\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.93870\n",
      "1875/1875 [==============================] - 423s 226ms/step - loss: 0.1547 - accuracy: 0.9437 - categorical_crossentropy: 0.1547 - categorical_accuracy: 0.9437 - val_loss: 0.2004 - val_accuracy: 0.9291 - val_categorical_crossentropy: 0.2005 - val_categorical_accuracy: 0.9291\n",
      "Epoch 17/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9466 - categorical_crossentropy: 0.1497 - categorical_accuracy: 0.9466\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.93870\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1875/1875 [==============================] - 420s 224ms/step - loss: 0.1497 - accuracy: 0.9466 - categorical_crossentropy: 0.1497 - categorical_accuracy: 0.9466 - val_loss: 0.1967 - val_accuracy: 0.9285 - val_categorical_crossentropy: 0.1968 - val_categorical_accuracy: 0.9285\n",
      "Epoch 18/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9469 - categorical_crossentropy: 0.1450 - categorical_accuracy: 0.9469\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.93870\n",
      "1875/1875 [==============================] - 422s 225ms/step - loss: 0.1450 - accuracy: 0.9469 - categorical_crossentropy: 0.1450 - categorical_accuracy: 0.9469 - val_loss: 0.1781 - val_accuracy: 0.9385 - val_categorical_crossentropy: 0.1781 - val_categorical_accuracy: 0.9385\n",
      "Epoch 19/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 0.9499 - categorical_crossentropy: 0.1387 - categorical_accuracy: 0.9499 ETA: 1s - loss: 0.1388 - accuracy: 0.9499 - categorical_crossentropy: 0.1388 - categorical_\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.93870 to 0.94290, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/wide_resnet_adam-19-0.94.hdf5\n",
      "1875/1875 [==============================] - 419s 224ms/step - loss: 0.1387 - accuracy: 0.9499 - categorical_crossentropy: 0.1387 - categorical_accuracy: 0.9499 - val_loss: 0.1660 - val_accuracy: 0.9429 - val_categorical_crossentropy: 0.1660 - val_categorical_accuracy: 0.9429\n",
      "Epoch 20/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1329 - accuracy: 0.9520 - categorical_crossentropy: 0.1329 - categorical_accuracy: 0.9520\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.94290\n",
      "1875/1875 [==============================] - 422s 225ms/step - loss: 0.1329 - accuracy: 0.9520 - categorical_crossentropy: 0.1329 - categorical_accuracy: 0.9520 - val_loss: 0.1795 - val_accuracy: 0.9361 - val_categorical_crossentropy: 0.1796 - val_categorical_accuracy: 0.9361\n",
      "Epoch 21/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9530 - categorical_crossentropy: 0.1283 - categorical_accuracy: 0.9530\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.94290\n",
      "1875/1875 [==============================] - 424s 226ms/step - loss: 0.1283 - accuracy: 0.9530 - categorical_crossentropy: 0.1283 - categorical_accuracy: 0.9530 - val_loss: 0.1931 - val_accuracy: 0.9308 - val_categorical_crossentropy: 0.1933 - val_categorical_accuracy: 0.9308\n",
      "Epoch 22/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9536 - categorical_crossentropy: 0.1268 - categorical_accuracy: 0.9536\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.94290\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1875/1875 [==============================] - 423s 226ms/step - loss: 0.1268 - accuracy: 0.9536 - categorical_crossentropy: 0.1268 - categorical_accuracy: 0.9536 - val_loss: 0.1672 - val_accuracy: 0.9426 - val_categorical_crossentropy: 0.1671 - val_categorical_accuracy: 0.9426\n",
      "Epoch 23/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9562 - categorical_crossentropy: 0.1211 - categorical_accuracy: 0.9562\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.94290\n",
      "1875/1875 [==============================] - 419s 223ms/step - loss: 0.1210 - accuracy: 0.9562 - categorical_crossentropy: 0.1210 - categorical_accuracy: 0.9562 - val_loss: 0.1788 - val_accuracy: 0.9378 - val_categorical_crossentropy: 0.1790 - val_categorical_accuracy: 0.9378\n",
      "Epoch 24/50\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9565 - categorical_crossentropy: 0.1178 - categorical_accuracy: 0.9565\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.94290\n",
      "1875/1875 [==============================] - 423s 225ms/step - loss: 0.1179 - accuracy: 0.9565 - categorical_crossentropy: 0.1179 - categorical_accuracy: 0.9565 - val_loss: 0.1692 - val_accuracy: 0.9414 - val_categorical_crossentropy: 0.1692 - val_categorical_accuracy: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing training images: 60000it [00:05, 10836.66it/s]\n",
      "Resizing training images: 10000it [00:00, 13203.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.7528 - accuracy: 0.7252 - categorical_crossentropy: 0.7528 - categorical_accuracy: 0.7252\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.10000, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-01-0.10.hdf5\n",
      "3750/3750 [==============================] - 604s 161ms/step - loss: 0.7528 - accuracy: 0.7252 - categorical_crossentropy: 0.7528 - categorical_accuracy: 0.7252 - val_loss: 2.7076 - val_accuracy: 0.1000 - val_categorical_crossentropy: 2.7076 - val_categorical_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.4847 - accuracy: 0.8241 - categorical_crossentropy: 0.4847 - categorical_accuracy: 0.8241\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.10000 to 0.83700, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-02-0.84.hdf5\n",
      "3750/3750 [==============================] - 604s 161ms/step - loss: 0.4846 - accuracy: 0.8241 - categorical_crossentropy: 0.4846 - categorical_accuracy: 0.8241 - val_loss: 0.4514 - val_accuracy: 0.8370 - val_categorical_crossentropy: 0.4514 - val_categorical_accuracy: 0.8370\n",
      "Epoch 3/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.4076 - accuracy: 0.8527 - categorical_crossentropy: 0.4076 - categorical_accuracy: 0.8527\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.83700 to 0.87540, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-03-0.88.hdf5\n",
      "3750/3750 [==============================] - 606s 162ms/step - loss: 0.4076 - accuracy: 0.8527 - categorical_crossentropy: 0.4076 - categorical_accuracy: 0.8527 - val_loss: 0.4092 - val_accuracy: 0.8754 - val_categorical_crossentropy: 0.4092 - val_categorical_accuracy: 0.8754\n",
      "Epoch 4/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.3628 - accuracy: 0.8678 - categorical_crossentropy: 0.3628 - categorical_accuracy: 0.8678\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.87540\n",
      "3750/3750 [==============================] - 604s 161ms/step - loss: 0.3627 - accuracy: 0.8679 - categorical_crossentropy: 0.3627 - categorical_accuracy: 0.8679 - val_loss: 0.3953 - val_accuracy: 0.8581 - val_categorical_crossentropy: 0.3953 - val_categorical_accuracy: 0.8581\n",
      "\n",
      "Epoch 00005: starting stochastic weight averaging\n",
      "Epoch 5/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.8778 - categorical_crossentropy: 0.3383 - categorical_accuracy: 0.8778\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.87540 to 0.90050, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-05-0.90.hdf5\n",
      "3750/3750 [==============================] - 606s 162ms/step - loss: 0.3383 - accuracy: 0.8777 - categorical_crossentropy: 0.3383 - categorical_accuracy: 0.8777 - val_loss: 0.2955 - val_accuracy: 0.9005 - val_categorical_crossentropy: 0.2955 - val_categorical_accuracy: 0.9005\n",
      "Epoch 6/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.3160 - accuracy: 0.8851 - categorical_crossentropy: 0.3160 - categorical_accuracy: 0.8851\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.90050\n",
      "3750/3750 [==============================] - 604s 161ms/step - loss: 0.3160 - accuracy: 0.8851 - categorical_crossentropy: 0.3160 - categorical_accuracy: 0.8851 - val_loss: 0.2795 - val_accuracy: 0.8987 - val_categorical_crossentropy: 0.2795 - val_categorical_accuracy: 0.8987\n",
      "Epoch 7/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8917 - categorical_crossentropy: 0.3006 - categorical_accuracy: 0.8917\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.90050\n",
      "3750/3750 [==============================] - 606s 161ms/step - loss: 0.3006 - accuracy: 0.8917 - categorical_crossentropy: 0.3006 - categorical_accuracy: 0.8917 - val_loss: 0.3211 - val_accuracy: 0.8813 - val_categorical_crossentropy: 0.3211 - val_categorical_accuracy: 0.8813\n",
      "Epoch 8/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2884 - accuracy: 0.8947 - categorical_crossentropy: 0.2884 - categorical_accuracy: 0.8947\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.90050 to 0.90190, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-08-0.90.hdf5\n",
      "3750/3750 [==============================] - 602s 161ms/step - loss: 0.2884 - accuracy: 0.8947 - categorical_crossentropy: 0.2884 - categorical_accuracy: 0.8947 - val_loss: 0.2670 - val_accuracy: 0.9019 - val_categorical_crossentropy: 0.2670 - val_categorical_accuracy: 0.9019\n",
      "Epoch 9/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2812 - accuracy: 0.8980 - categorical_crossentropy: 0.2812 - categorical_accuracy: 0.8980\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.90190 to 0.90400, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-09-0.90.hdf5\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2812 - accuracy: 0.8980 - categorical_crossentropy: 0.2812 - categorical_accuracy: 0.8980 - val_loss: 0.2652 - val_accuracy: 0.9040 - val_categorical_crossentropy: 0.2652 - val_categorical_accuracy: 0.9040\n",
      "Epoch 10/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9030 - categorical_crossentropy: 0.2668 - categorical_accuracy: 0.9030\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.90400\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2668 - accuracy: 0.9030 - categorical_crossentropy: 0.2668 - categorical_accuracy: 0.9030 - val_loss: 0.2524 - val_accuracy: 0.9040 - val_categorical_crossentropy: 0.2524 - val_categorical_accuracy: 0.9040\n",
      "Epoch 11/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.9064 - categorical_crossentropy: 0.2570 - categorical_accuracy: 0.9064\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.90400 to 0.91150, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-11-0.91.hdf5\n",
      "3750/3750 [==============================] - 601s 160ms/step - loss: 0.2569 - accuracy: 0.9065 - categorical_crossentropy: 0.2569 - categorical_accuracy: 0.9065 - val_loss: 0.2424 - val_accuracy: 0.9115 - val_categorical_crossentropy: 0.2424 - val_categorical_accuracy: 0.9115\n",
      "Epoch 12/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.9078 - categorical_crossentropy: 0.2525 - categorical_accuracy: 0.9078\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.91150\n",
      "3750/3750 [==============================] - 598s 160ms/step - loss: 0.2525 - accuracy: 0.9078 - categorical_crossentropy: 0.2525 - categorical_accuracy: 0.9078 - val_loss: 0.2415 - val_accuracy: 0.9109 - val_categorical_crossentropy: 0.2415 - val_categorical_accuracy: 0.9109\n",
      "Epoch 13/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9106 - categorical_crossentropy: 0.2459 - categorical_accuracy: 0.9106\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.91150\n",
      "3750/3750 [==============================] - 600s 160ms/step - loss: 0.2459 - accuracy: 0.9106 - categorical_crossentropy: 0.2459 - categorical_accuracy: 0.9106 - val_loss: 0.2904 - val_accuracy: 0.8947 - val_categorical_crossentropy: 0.2904 - val_categorical_accuracy: 0.8947\n",
      "Epoch 14/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2375 - accuracy: 0.9120 - categorical_crossentropy: 0.2375 - categorical_accuracy: 0.9120\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.91150\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2374 - accuracy: 0.9121 - categorical_crossentropy: 0.2374 - categorical_accuracy: 0.9121 - val_loss: 0.2389 - val_accuracy: 0.9098 - val_categorical_crossentropy: 0.2389 - val_categorical_accuracy: 0.9098\n",
      "Epoch 15/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.9152 - categorical_crossentropy: 0.2316 - categorical_accuracy: 0.9152\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.91150 to 0.91320, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-15-0.91.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 601s 160ms/step - loss: 0.2316 - accuracy: 0.9152 - categorical_crossentropy: 0.2316 - categorical_accuracy: 0.9152 - val_loss: 0.2326 - val_accuracy: 0.9132 - val_categorical_crossentropy: 0.2326 - val_categorical_accuracy: 0.9132\n",
      "Epoch 16/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2278 - accuracy: 0.9157 - categorical_crossentropy: 0.2278 - categorical_accuracy: 0.9157\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.91320\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2278 - accuracy: 0.9157 - categorical_crossentropy: 0.2278 - categorical_accuracy: 0.9157 - val_loss: 0.2614 - val_accuracy: 0.9039 - val_categorical_crossentropy: 0.2614 - val_categorical_accuracy: 0.9039\n",
      "Epoch 17/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9183 - categorical_crossentropy: 0.2215 - categorical_accuracy: 0.9183\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.91320 to 0.91850, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-17-0.92.hdf5\n",
      "3750/3750 [==============================] - 598s 160ms/step - loss: 0.2215 - accuracy: 0.9183 - categorical_crossentropy: 0.2215 - categorical_accuracy: 0.9183 - val_loss: 0.2275 - val_accuracy: 0.9185 - val_categorical_crossentropy: 0.2275 - val_categorical_accuracy: 0.9185\n",
      "Epoch 18/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2182 - accuracy: 0.9197 - categorical_crossentropy: 0.2182 - categorical_accuracy: 0.9197\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.91850\n",
      "3750/3750 [==============================] - 600s 160ms/step - loss: 0.2182 - accuracy: 0.9197 - categorical_crossentropy: 0.2182 - categorical_accuracy: 0.9197 - val_loss: 0.2292 - val_accuracy: 0.9161 - val_categorical_crossentropy: 0.2292 - val_categorical_accuracy: 0.9161\n",
      "Epoch 19/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9198 - categorical_crossentropy: 0.2138 - categorical_accuracy: 0.9198\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.91850 to 0.92720, saving model to /home/cenk/Research/pre-trained-models/cv/fashion_mnist/mobile_net_adam-19-0.93.hdf5\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2138 - accuracy: 0.9198 - categorical_crossentropy: 0.2138 - categorical_accuracy: 0.9198 - val_loss: 0.2034 - val_accuracy: 0.9272 - val_categorical_crossentropy: 0.2034 - val_categorical_accuracy: 0.9272\n",
      "Epoch 20/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2071 - accuracy: 0.9238 - categorical_crossentropy: 0.2071 - categorical_accuracy: 0.9238\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.92720\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2071 - accuracy: 0.9237 - categorical_crossentropy: 0.2071 - categorical_accuracy: 0.9237 - val_loss: 0.2132 - val_accuracy: 0.9221 - val_categorical_crossentropy: 0.2132 - val_categorical_accuracy: 0.9221\n",
      "Epoch 21/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9243 - categorical_crossentropy: 0.2066 - categorical_accuracy: 0.9243\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.92720\n",
      "3750/3750 [==============================] - 599s 160ms/step - loss: 0.2065 - accuracy: 0.9244 - categorical_crossentropy: 0.2065 - categorical_accuracy: 0.9244 - val_loss: 0.2042 - val_accuracy: 0.9236 - val_categorical_crossentropy: 0.2042 - val_categorical_accuracy: 0.9236\n",
      "Epoch 22/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9266 - categorical_crossentropy: 0.2000 - categorical_accuracy: 0.9266\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.92720\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "3750/3750 [==============================] - 598s 160ms/step - loss: 0.2000 - accuracy: 0.9266 - categorical_crossentropy: 0.2000 - categorical_accuracy: 0.9266 - val_loss: 0.2063 - val_accuracy: 0.9236 - val_categorical_crossentropy: 0.2063 - val_categorical_accuracy: 0.9236\n",
      "Epoch 23/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9271 - categorical_crossentropy: 0.1974 - categorical_accuracy: 0.9271\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.92720\n",
      "3750/3750 [==============================] - 600s 160ms/step - loss: 0.1973 - accuracy: 0.9272 - categorical_crossentropy: 0.1973 - categorical_accuracy: 0.9272 - val_loss: 0.2012 - val_accuracy: 0.9259 - val_categorical_crossentropy: 0.2012 - val_categorical_accuracy: 0.9259\n",
      "Epoch 24/50\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9287 - categorical_crossentropy: 0.1935 - categorical_accuracy: 0.9287"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "histories = {}\n",
    "models = {}\n",
    "\n",
    "for opt_name, opt in optimizers.items():\n",
    "    '''\n",
    "    # Train capsule net\n",
    "    model_name = f'capsnet_{opt_name}'\n",
    "    model = WideResNet(opt)\n",
    "    history = model.train(data_generator, X_train, y_train, X_val, y_val,\n",
    "                          16, epochs, get_callbacks(model_name))\n",
    "    histories[model_name] = history.history\n",
    "    models[model_name] = model\n",
    "    '''\n",
    "    \n",
    "    # Train wide resnet net\n",
    "    model_name = f'wide_resnet_{opt_name}'\n",
    "    model = WideResNet(opt)\n",
    "    history = model.train(data_generator, X_train, y_train, X_val, y_val,\n",
    "                              32, epochs, get_callbacks(model_name))\n",
    "    histories[model_name] = history.history\n",
    "    models[model_name] = model\n",
    "\n",
    "    # Train mobile_net\n",
    "    model_name = f'mobile_net_{opt_name}'\n",
    "    model = MobileNET(opt)\n",
    "    history = model.train(data_generator, X_train, y_train, X_val, y_val,\n",
    "                            16, epochs, get_callbacks(model_name))\n",
    "    histories[model_name] = history.history\n",
    "    models[model_name] = model\n",
    "        \n",
    "    # Train a basic cnn\n",
    "    model_name = f'simple_cnn_{opt_name}'\n",
    "    model = SimpleCNN(opt)\n",
    "    history = model.train(data_generator, X_train, y_train, X_val, y_val,\n",
    "                            2048, epochs, get_callbacks(model_name))\n",
    "    histories[model_name] = history.history\n",
    "    models[model_name] = model\n",
    "    \n",
    "    # Train shufflenetv2\n",
    "    model_name = f'shuffle_netv2_{opt_name}'\n",
    "    model = ShuffleNetV2(opt)\n",
    "    model = ShuffleNetV2(opt)\n",
    "    history = model.train(data_generator, X_train, y_train, X_val, y_val,\n",
    "                              256, epochs, get_callbacks(model_name))\n",
    "    histories[model_name] = history.history\n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
